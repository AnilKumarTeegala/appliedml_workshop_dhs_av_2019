{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised ML : Classification : Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear regression:** continuous response is modeled as a linear combination of the features:\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1x$$\n",
    " \n",
    "**Logistic regression:** log-odds of a categorical response being \"true\" (1) is modeled as a linear combination of the features:\n",
    " \n",
    "$$\\log \\left({p\\over 1-p}\\right) = \\beta_0 + \\beta_1x$$\n",
    " \n",
    "This is called the **logit function**.\n",
    " \n",
    "Probability is sometimes written as pi:\n",
    " \n",
    "$$\\log \\left({\\pi\\over 1-\\pi}\\right) = \\beta_0 + \\beta_1x$$\n",
    " \n",
    "The equation can be rearranged into the **logistic function**:\n",
    " \n",
    "$$\\pi = \\frac{e^{\\beta_0 + \\beta_1x}} {1 + e^{\\beta_0 + \\beta_1x}}$$\n",
    "\n",
    "In other words:\n",
    " \n",
    " - Logistic regression outputs the **probabilities of a specific class**\n",
    " - Those probabilities can be converted into **class predictions**\n",
    " \n",
    "The **logistic function** has some nice properties:\n",
    "\n",
    " - Takes on an \"s\" shape\n",
    " - Output is bounded by 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:20:18.769080Z",
     "start_time": "2019-11-08T03:20:17.145290Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:20:18.784250Z",
     "start_time": "2019-11-08T03:20:18.770835Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "y_labels = np.array(['malignant' if item == 0 else 'benign' for item in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:20:18.790077Z",
     "start_time": "2019-11-08T03:20:18.786439Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Dataset for Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:20:18.797066Z",
     "start_time": "2019-11-08T03:20:18.792418Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([pd.DataFrame(X, columns=data.feature_names), \n",
    "                pd.DataFrame(y_labels.reshape(-1,1), columns=['has cancer'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:20:18.833452Z",
     "start_time": "2019-11-08T03:20:18.798960Z"
    }
   },
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Analysis\n",
    "\n",
    "### Question 1\n",
    "\n",
    "Import the data and do the following:\n",
    "\n",
    "* Examine the data types--there are many columns, so it might be wise to use value counts\n",
    "* Determine the distribution of each type of record\n",
    "* Encode the activity label as an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:20:18.854168Z",
     "start_time": "2019-11-08T03:20:18.836106Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Targets/Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:20:18.863814Z",
     "start_time": "2019-11-08T03:20:18.857784Z"
    }
   },
   "outputs": [],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:20:18.878084Z",
     "start_time": "2019-11-08T03:20:18.868057Z"
    }
   },
   "outputs": [],
   "source": [
    "df['has cancer'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "* Split the data into train and test data sets. This can be done using any method, but consider using Scikit-learn's `StratifiedShuffleSplit` to maintain the same ratio of predictor classes.\n",
    "* Regardless of methods used to split the data, compare the ratio of classes in both the train and test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:20:18.915062Z",
     "start_time": "2019-11-08T03:20:18.881826Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_labels, test_size=0.3, random_state=42)\n",
    "print('Training dataset shape:', X_train.shape, '\\tTest dataset shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "* Fit a logistic regression model without any regularization using all of the features. \n",
    "* Using cross validation to determine the hyperparameters, fit models using L1, and L2 regularization. Store each of these models as well. Note the limitations on regularizations. The regularized models, in particular the L1 model, will probably take a while to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:20:18.984371Z",
     "start_time": "2019-11-08T03:20:18.917841Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:20:19.201669Z",
     "start_time": "2019-11-08T03:20:18.986962Z"
    }
   },
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:20:24.343872Z",
     "start_time": "2019-11-08T03:20:19.204385Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# L1 regularized logistic regression\n",
    "lr_l1 = LogisticRegressionCV(Cs=10, cv=4, penalty='l1', solver='liblinear').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:20:25.004084Z",
     "start_time": "2019-11-08T03:20:24.345654Z"
    }
   },
   "outputs": [],
   "source": [
    "# L2 regularized logistic regression\n",
    "lr_l2 = LogisticRegressionCV(Cs=10, cv=4, penalty='l2').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Compare the magnitudes of the coefficients for each of the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:20:25.026818Z",
     "start_time": "2019-11-08T03:20:25.005925Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine all the coefficients into a dataframe\n",
    "coefficients = list()\n",
    "\n",
    "coeff_labels = ['lr', 'l1', 'l2']\n",
    "coeff_models = [lr, lr_l1, lr_l2]\n",
    "\n",
    "for lab,mod in zip(coeff_labels, coeff_models):\n",
    "    coeffs = mod.coef_\n",
    "    coeff_label = pd.MultiIndex(levels=[[lab], [0]], \n",
    "                                 labels=[[0], [0]])\n",
    "    coefficients.append(pd.DataFrame(coeffs.T, columns=coeff_label))\n",
    "\n",
    "coefficients = pd.concat(coefficients, axis=1)\n",
    "\n",
    "coefficients.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:20:25.246926Z",
     "start_time": "2019-11-08T03:20:25.029302Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:20:25.585160Z",
     "start_time": "2019-11-08T03:20:25.248961Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "#axList = axList.flatten()\n",
    "fig.set_size_inches(10,10)\n",
    "\n",
    "data = coefficients.xs(0, level=1, axis=1)\n",
    "data.plot(marker='o', ls='', ms=5.0, ax=ax, legend=False)\n",
    "\n",
    "ax.legend(loc=4)\n",
    "\n",
    "ax.set(title='Coefficient Set ')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "* Predict and store the class for each model.\n",
    "* Also store the probability for the predicted class for each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:20:25.590373Z",
     "start_time": "2019-11-08T03:20:25.587151Z"
    }
   },
   "outputs": [],
   "source": [
    "test_predictions = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:20:25.599543Z",
     "start_time": "2019-11-08T03:20:25.592475Z"
    }
   },
   "outputs": [],
   "source": [
    "test_predictions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "For each model, calculate the following error metrics: \n",
    "\n",
    "* accuracy\n",
    "* precision\n",
    "* recall\n",
    "* fscore\n",
    "* confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:20:25.605775Z",
     "start_time": "2019-11-08T03:20:25.601667Z"
    }
   },
   "outputs": [],
   "source": [
    "import model_evaluation_utils as meu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:20:25.614115Z",
     "start_time": "2019-11-08T03:20:25.607306Z"
    }
   },
   "outputs": [],
   "source": [
    "meu.get_metrics(true_labels=y_test, predicted_labels=test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:20:25.760792Z",
     "start_time": "2019-11-08T03:20:25.615811Z"
    }
   },
   "outputs": [],
   "source": [
    "meu.display_confusion_matrix(true_labels=y_test, predicted_labels=test_predictions,\n",
    "                             classes=data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:20:25.763122Z",
     "start_time": "2019-11-08T03:20:17.280Z"
    }
   },
   "outputs": [],
   "source": [
    "meu.display_classification_report(true_labels=y_test, predicted_labels=test_predictions,\n",
    "                                  classes=data.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:06:34.449526Z",
     "start_time": "2019-11-08T03:06:34.445874Z"
    }
   },
   "source": [
    "### Question 7\n",
    " Identify highly correlated columns and drop those columns before building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:20:25.764731Z",
     "start_time": "2019-11-08T03:20:17.291Z"
    }
   },
   "outputs": [],
   "source": [
    "data2.loc[:,~data2.columns.isin(['has cancer'])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:20:25.766139Z",
     "start_time": "2019-11-08T03:20:17.293Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "#threshold with .7\n",
    "\n",
    "sel = VarianceThreshold(threshold=(.7 * (1 - .7)))\n",
    "\n",
    "data2 = df.copy()\n",
    "data_new = pd.DataFrame(sel.fit_transform(data2.loc[:,~data2.columns.isin(['has cancer'])]))\n",
    "\n",
    "# train-test split\n",
    "X_new,X_test_new, Y_new,Y_test_new = train_test_split(data_new, data2['has cancer'].tolist(), test_size=0.3, random_state=42)\n",
    "print('Training dataset shape:', X_new.shape, '\\tTest dataset shape:', X_test_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "+ Predict and store the class for each model.\n",
    "+ Also store the probability for the predicted class for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-08T03:19:16.682703Z",
     "start_time": "2019-11-08T03:19:16.678246Z"
    }
   },
   "source": [
    "### Question 9\n",
    "\n",
    "For each model, calculate the following error metrics: \n",
    "\n",
    "* accuracy\n",
    "* precision\n",
    "* recall\n",
    "* fscore\n",
    "* confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
